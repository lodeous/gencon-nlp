{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import string\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from time import time\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "from utils import prep_text, prep_data, vec_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in all talks for the 20 most frequent speakers\n",
    "n_speakers = 20\n",
    "summary = pd.read_json(\"../merged_summary_topics.json\")\n",
    "top_speakers = summary[\"Speaker\"].value_counts()[:n_speakers].index.to_list()\n",
    "\n",
    "talks = {}\n",
    "for name in top_speakers:\n",
    "    talks[name] = []\n",
    "    for filename in summary[summary[\"Speaker\"] == name][\"File\"]:\n",
    "        with open(\"../\" + filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "            processed = simple_preprocess(text)\n",
    "            if len(text):\n",
    "                talks[name].append(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification with one HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the first 10 of President Monson's talks\n",
    "name = 'Thomas S. Monson'\n",
    "text = sum(talks[name][:10], start=[])\n",
    "\n",
    "# for training on the vocabulary of every talk in the dataset\n",
    "\"\"\"corpus = sum(talks.values(), start=[])\n",
    "dictionary = corpora.Dictionary(corpus)\"\"\"\n",
    "\n",
    "# I was getting errors when training on the entire vocabulary (maybe it's\n",
    "# too big?) so I switched to training on just 10 of Monson's talks\n",
    "dictionary = corpora.Dictionary([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(n_components=5, n_iter=100,\n",
       "               random_state=RandomState(MT19937) at 0x7F560404B740)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = hmm.MultinomialHMM(n_components=5, n_iter=100)\n",
    "model.fit(prep_text(text, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for a talk from Monson in the training data: -12452.11667042868\n",
      "Score for a talk from Monson not in training data: -18530.168671097912\n",
      "Thomas S. Monson : -12452.11667042868\n",
      "Gordon B. Hinckley : -18278.154742686434\n",
      "James E. Faust : -5338.276916207026\n",
      "Boyd K. Packer : -11903.825848543132\n",
      "Henry B. Eyring : -12740.307297212075\n",
      "L. Tom Perry : -1362.8999517689779\n",
      "M. Russell Ballard : -2605.5008951763675\n",
      "Russell M. Nelson : -10634.035300107926\n",
      "Dallin H. Oaks : -4334.680069573178\n",
      "Spencer W. Kimball : -28589.126197459103\n",
      "Ezra Taft Benson : -19480.948601500815\n",
      "Dieter F. Uchtdorf : -9006.251824468758\n",
      "Richard G. Scott : -3480.3292300853864\n",
      "David B. Haight : -15472.878548559429\n",
      "Robert D. Hales : -9508.757406609\n",
      "Marion G. Romney : -17526.393818300054\n",
      "Joseph B. Wirthlin : -5728.436822951388\n",
      "Howard W. Hunter : -15744.028627505291\n",
      "Jeffrey R. Holland : -17431.3873426812\n",
      "Neal A. Maxwell : -5531.255997349309\n",
      "\n",
      "Speaker with the maximum score: L. Tom Perry with score = -1362.8999517689779\n"
     ]
    }
   ],
   "source": [
    "# find the talk with the highest log probability\n",
    "print(\"Score for a talk from Monson in the training data:\",\n",
    "     model.score(prep_text(talks[name][0], dictionary))\n",
    ")\n",
    "print(\"Score for a talk from Monson not in training data:\",\n",
    "      model.score(prep_text(talks[name][11], dictionary)))\n",
    "\n",
    "max_score, max_name = -np.inf, None\n",
    "for name in list(talks.keys()):\n",
    "    score = model.score(prep_text(talks[name][0], dictionary))\n",
    "    print(name, \":\", score)\n",
    "    \n",
    "    if score > max_score:\n",
    "        max_score, max_name = score, name\n",
    "\n",
    "print(\n",
    "    f\"\\nSpeaker with the maximum score: {max_name} with score = {max_score}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us saw surrender to learn winds drew world our statement on he above shall me that master to on he of their me that you by each amen stooped for have bus the hope of such hand years they for death of faith who the night of replace nose he time back parables one tree and clean that but of still into the perfection its by the waters to the are eternal will scant into handsome whom of love never the best will giant depart and the mark of my what he mother for moment witness him train to hall'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the previously trained model, sample 100 words\n",
    "\" \".join([dictionary[i] for i in model.sample(100)[0].flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isms ony t isg donmaonsat on the to oice is tlisesncome theawe hale on purepeas of wrass to the fand'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols, obs = prep_data(\"../data/2000.txt\")\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=50, n_iter=20)\n",
    "model.fit(obs.reshape(-1, 1))\n",
    "X, _ = model.sample(100)\n",
    "X = X.flatten()\n",
    "\"\".join([symbols[i] for i in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name, training_size):\n",
    "    text = sum(talks[name][:training_size], start=[])\n",
    "    dictionary = corpora.Dictionary([text])\n",
    "    \n",
    "    model = hmm.MultinomialHMM(n_components=10, n_iter=100)\n",
    "    model.fit(prep_text(text, dictionary))\n",
    "    return model, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  20 | elapsed:  7.7min remaining: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  20 | elapsed: 14.4min remaining: 17.6min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed: 15.0min remaining: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  20 | elapsed: 15.4min remaining:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed: 15.9min remaining:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed: 19.1min remaining:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 20.2min finished\n"
     ]
    }
   ],
   "source": [
    "# train 20 models, one for each speaker\n",
    "training_size = 40\n",
    "speakers = list(talks.keys())\n",
    "\n",
    "models = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(train_model, training_size=training_size)\n",
    "    )(name) for name in speakers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Thomas S. Monson': 111, 'Gordon B. Hinckley': 56}); % correct = 0.6646706586826348\n",
      "\n",
      "Gordon B. Hinckley: Counter({'Gordon B. Hinckley': 160, 'Thomas S. Monson': 7}); % correct = 0.9580838323353293\n",
      "\n",
      "Overall accuracy: 0.811377245508982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.3s finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained models on two speakers\n",
    "\n",
    "top_n_speakers = 2\n",
    "\n",
    "p_s = np.array([len(talks[name]) for name in speakers], dtype=float)\n",
    "p_s /= np.sum(p_s)\n",
    "log_p_s = np.log(p_s[:top_n_speakers])\n",
    "\n",
    "def eval_model(name, training_size):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][training_size:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([model.score(prep_text(talk, dictionary)) for model, dictionary in models[:top_n_speakers]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_p_s\n",
    "        \n",
    "        closest_speaker = speakers[np.argmax(p_s_t)]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(eval_model, training_size=training_size)\n",
    "    )(name) for name in speakers[:top_n_speakers]\n",
    ")\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for speaker, (counts, accuracy, _scores)in zip(speakers, results):\n",
    "    total_correct += counts[speaker]\n",
    "    total += sum(counts.values())\n",
    "    \n",
    "    print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Thomas S. Monson': 40}); % correct = 1.0\n",
      "[-16406.1503697  -25088.75081924]\n",
      "\n",
      "Gordon B. Hinckley: Counter({'Gordon B. Hinckley': 38, 'Thomas S. Monson': 2}); % correct = 0.95\n",
      "[-22884.90250718 -17270.91751101]\n",
      "\n",
      "Overall accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "# test on training data\n",
    "\n",
    "top_n_speakers = 2\n",
    "\n",
    "p_s = np.array([len(talks[name]) for name in speakers], dtype=float)\n",
    "p_s /= np.sum(p_s)\n",
    "log_p_s = np.log(p_s[:top_n_speakers])\n",
    "\n",
    "def eval_model_train_set(name, training_size):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][:training_size]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([model.score(prep_text(talk, dictionary)) for model, dictionary in models[:top_n_speakers]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_p_s\n",
    "        \n",
    "        closest_speaker = speakers[np.argmax(p_s_t)]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(eval_model_train_set, training_size=training_size)\n",
    "    )(name) for name in speakers[:top_n_speakers]\n",
    ")\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for speaker, (counts, accuracy, _scores)in zip(speakers, results):\n",
    "    total_correct += counts[speaker]\n",
    "    total += sum(counts.values())\n",
    "    \n",
    "    print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "    print(_scores)\n",
    "    print()\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gordon B. Hinckley: Counter({'Gordon B. Hinckley': 100, 'James E. Faust': 67}); % correct = 0.5988023952095808\n",
      "\n",
      "James E. Faust: Counter({'James E. Faust': 55, 'Gordon B. Hinckley': 2}); % correct = 0.9649122807017544\n",
      "\n",
      "Overall accuracy: 0.6919642857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    7.4s finished\n"
     ]
    }
   ],
   "source": [
    "# test on other sets of two speakers\n",
    "\n",
    "top_n_speakers = 2\n",
    "\n",
    "p_s = np.array([len(talks[name]) for name in speakers], dtype=float)\n",
    "p_s /= np.sum(p_s)\n",
    "log_p_s = np.log(p_s[1:top_n_speakers+1])\n",
    "\n",
    "def eval_model(name, training_size):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][training_size:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([model.score(prep_text(talk, dictionary)) for model, dictionary in models[1:top_n_speakers+1]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_p_s\n",
    "        \n",
    "        closest_speaker = speakers[np.argmax(p_s_t)+1]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(eval_model, training_size=training_size)\n",
    "    )(name) for name in speakers[1:top_n_speakers+1]\n",
    ")\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for speaker, (counts, accuracy, _scores)in zip(\n",
    "    speakers[1:top_n_speakers+1], results):\n",
    "    total_correct += counts[speaker]\n",
    "    total += sum(counts.values())\n",
    "    \n",
    "    print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James E. Faust: Counter({'James E. Faust': 52, 'Boyd K. Packer': 5}); % correct = 0.9122807017543859\n",
      "\n",
      "Boyd K. Packer: Counter({'Boyd K. Packer': 26, 'James E. Faust': 20}); % correct = 0.5652173913043478\n",
      "\n",
      "Overall accuracy: 0.7572815533980582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "# test on yet another set of two speakers\n",
    "\n",
    "top_n_speakers = 2\n",
    "\n",
    "p_s = np.array([len(talks[name]) for name in speakers], dtype=float)\n",
    "p_s /= np.sum(p_s)\n",
    "log_p_s = np.log(p_s[2:top_n_speakers+2])\n",
    "\n",
    "def eval_model(name, training_size):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][training_size:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([model.score(prep_text(talk, dictionary)) for model, dictionary in models[2:top_n_speakers+2]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_p_s\n",
    "        \n",
    "        closest_speaker = speakers[np.argmax(p_s_t)+2]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(eval_model, training_size=training_size)\n",
    "    )(name) for name in speakers[2:top_n_speakers+2]\n",
    ")\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for speaker, (counts, accuracy, _scores)in zip(\n",
    "    speakers[2:top_n_speakers+2], results):\n",
    "    total_correct += counts[speaker]\n",
    "    total += sum(counts.values())\n",
    "    \n",
    "    print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   25.4s\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   33.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  20 | elapsed:   43.6s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  20 | elapsed:   45.3s remaining:   55.4s\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   46.8s remaining:   38.3s\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  20 | elapsed:   52.0s remaining:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:   54.0s remaining:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:   54.7s remaining:    9.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Marion G. Romney': 73, 'Dieter F. Uchtdorf': 21, 'Dallin H. Oaks': 15, 'Thomas S. Monson': 11, 'L. Tom Perry': 9, 'M. Russell Ballard': 8, 'James E. Faust': 6, 'David B. Haight': 6, 'Richard G. Scott': 5, 'Howard W. Hunter': 3, 'Gordon B. Hinckley': 3, 'Henry B. Eyring': 3, 'Ezra Taft Benson': 2, 'Jeffrey R. Holland': 1, 'Joseph B. Wirthlin': 1}); % correct = 0.0658682634730539\n",
      "\n",
      "Gordon B. Hinckley: Counter({'Marion G. Romney': 65, 'Gordon B. Hinckley': 48, 'Dallin H. Oaks': 20, 'David B. Haight': 7, 'L. Tom Perry': 7, 'Dieter F. Uchtdorf': 5, 'Ezra Taft Benson': 5, 'Richard G. Scott': 3, 'James E. Faust': 3, 'Jeffrey R. Holland': 1, 'M. Russell Ballard': 1, 'Boyd K. Packer': 1, 'Howard W. Hunter': 1}); % correct = 0.2874251497005988\n",
      "\n",
      "James E. Faust: Counter({'Marion G. Romney': 28, 'Dallin H. Oaks': 10, 'Dieter F. Uchtdorf': 7, 'James E. Faust': 5, 'David B. Haight': 3, 'Richard G. Scott': 2, 'Jeffrey R. Holland': 1, 'M. Russell Ballard': 1}); % correct = 0.08771929824561403\n",
      "\n",
      "Boyd K. Packer: Counter({'Marion G. Romney': 23, 'Dallin H. Oaks': 8, 'Boyd K. Packer': 6, 'Richard G. Scott': 2, 'L. Tom Perry': 2, 'James E. Faust': 2, 'M. Russell Ballard': 1, 'Ezra Taft Benson': 1, 'Henry B. Eyring': 1}); % correct = 0.13043478260869565\n",
      "\n",
      "Henry B. Eyring: Counter({'Henry B. Eyring': 34, 'Marion G. Romney': 3, 'Dallin H. Oaks': 1, 'David B. Haight': 1, 'Dieter F. Uchtdorf': 1}); % correct = 0.85\n",
      "\n",
      "L. Tom Perry: Counter({'L. Tom Perry': 20, 'Marion G. Romney': 12, 'Dallin H. Oaks': 9, 'James E. Faust': 1, 'David B. Haight': 1, 'M. Russell Ballard': 1, 'Dieter F. Uchtdorf': 1}); % correct = 0.4444444444444444\n",
      "\n",
      "M. Russell Ballard: Counter({'M. Russell Ballard': 10, 'Dallin H. Oaks': 10, 'Richard G. Scott': 4, 'Marion G. Romney': 3, 'Dieter F. Uchtdorf': 3, 'David B. Haight': 2, 'L. Tom Perry': 2, 'James E. Faust': 2}); % correct = 0.2777777777777778\n",
      "\n",
      "Russell M. Nelson: Counter({'Dallin H. Oaks': 9, 'Marion G. Romney': 8, 'Dieter F. Uchtdorf': 6, 'James E. Faust': 2, 'Henry B. Eyring': 1, 'Russell M. Nelson': 1, 'Ezra Taft Benson': 1}); % correct = 0.03571428571428571\n",
      "\n",
      "Dallin H. Oaks: Counter({'Dallin H. Oaks': 24, 'Marion G. Romney': 2, 'Richard G. Scott': 1, 'James E. Faust': 1, 'Jeffrey R. Holland': 1}); % correct = 0.8275862068965517\n",
      "\n",
      "Spencer W. Kimball: Counter({'Marion G. Romney': 9, 'M. Russell Ballard': 6, 'David B. Haight': 3, 'Ezra Taft Benson': 2, 'James E. Faust': 2, 'Spencer W. Kimball': 2, 'Dallin H. Oaks': 2, 'L. Tom Perry': 1, 'Dieter F. Uchtdorf': 1, 'Howard W. Hunter': 1}); % correct = 0.06896551724137931\n",
      "\n",
      "Ezra Taft Benson: Counter({'Ezra Taft Benson': 10, 'Marion G. Romney': 4, 'Dallin H. Oaks': 4, 'David B. Haight': 1, 'M. Russell Ballard': 1}); % correct = 0.5\n",
      "\n",
      "David B. Haight: Counter({'David B. Haight': 11, 'Marion G. Romney': 3, 'Dallin H. Oaks': 2, 'Dieter F. Uchtdorf': 1, 'M. Russell Ballard': 1, 'Henry B. Eyring': 1}); % correct = 0.5789473684210527\n",
      "\n",
      "Dieter F. Uchtdorf: Counter({'Dieter F. Uchtdorf': 14, 'Marion G. Romney': 2, 'Dallin H. Oaks': 1}); % correct = 0.8235294117647058\n",
      "\n",
      "Richard G. Scott: Counter({'Richard G. Scott': 19}); % correct = 1.0\n",
      "\n",
      "Robert D. Hales: Counter({'Dieter F. Uchtdorf': 6, 'Dallin H. Oaks': 5, 'Marion G. Romney': 2, 'Robert D. Hales': 2, 'Henry B. Eyring': 1, 'L. Tom Perry': 1, 'Ezra Taft Benson': 1}); % correct = 0.1111111111111111\n",
      "\n",
      "Marion G. Romney: Counter({'Marion G. Romney': 10, 'Howard W. Hunter': 2, 'L. Tom Perry': 1, 'David B. Haight': 1, 'Dallin H. Oaks': 1, 'M. Russell Ballard': 1, 'James E. Faust': 1}); % correct = 0.5882352941176471\n",
      "\n",
      "Joseph B. Wirthlin: Counter({'Dieter F. Uchtdorf': 6, 'Marion G. Romney': 4, 'Dallin H. Oaks': 1, 'Richard G. Scott': 1, 'David B. Haight': 1}); % correct = 0.0\n",
      "\n",
      "Howard W. Hunter: Counter({'Marion G. Romney': 3, 'James E. Faust': 3, 'Dieter F. Uchtdorf': 1, 'Howard W. Hunter': 1, 'M. Russell Ballard': 1, 'Dallin H. Oaks': 1, 'Joseph B. Wirthlin': 1}); % correct = 0.09090909090909091\n",
      "\n",
      "Jeffrey R. Holland: Counter({'Marion G. Romney': 5, 'Jeffrey R. Holland': 2, 'L. Tom Perry': 1, 'Dieter F. Uchtdorf': 1}); % correct = 0.2222222222222222\n",
      "\n",
      "Neal A. Maxwell: Counter({'Marion G. Romney': 7, 'Dieter F. Uchtdorf': 2, 'Neal A. Maxwell': 1}); % correct = 0.1\n",
      "\n",
      "Overall accuracy: 0.28983688833124216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "# evaluate the trained models on all the speakers\n",
    "\n",
    "top_n_speakers = 20\n",
    "\n",
    "p_s = np.array([len(talks[name]) for name in speakers], dtype=float)\n",
    "p_s /= np.sum(p_s)\n",
    "log_p_s = np.log(p_s[:top_n_speakers])\n",
    "\n",
    "def eval_model(name, training_size):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][training_size:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([model.score(prep_text(talk, dictionary)) for model, dictionary in models[:top_n_speakers]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_p_s\n",
    "        \n",
    "        closest_speaker = speakers[np.argmax(p_s_t)]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(eval_model, training_size=training_size)\n",
    "    )(name) for name in speakers[:top_n_speakers]\n",
    ")\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for speaker, (counts, accuracy, _scores)in zip(speakers, results):\n",
    "    total_correct += counts[speaker]\n",
    "    total += sum(counts.values())\n",
    "    \n",
    "    print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
