{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import string\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from time import time\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "\n",
    "from utils import prep_text, prep_data, vec_translate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in all talks for the 20 most frequent speakers\n",
    "n_speakers = 20\n",
    "summary = pd.read_json(\"../merged_summary_topics.json\")\n",
    "top_speakers = summary[\"Speaker\"].value_counts()[:n_speakers].index.to_list()\n",
    "\n",
    "talks = {}\n",
    "for name in top_speakers:\n",
    "    talks[name] = []\n",
    "    for filename in summary[summary[\"Speaker\"] == name][\"File\"]:\n",
    "        with open(\"../\" + filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "            processed = simple_preprocess(text)\n",
    "            if len(text):\n",
    "                talks[name].append(processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the first 10 of President Monson's talks\n",
    "name = 'Thomas S. Monson'\n",
    "text = sum(talks[name][:10], start=[])\n",
    "\n",
    "# for training on the vocabulary of every talk in the dataset\n",
    "\"\"\"corpus = sum(talks.values(), start=[])\n",
    "dictionary = corpora.Dictionary(corpus)\"\"\"\n",
    "\n",
    "# I was getting errors when training on the entire vocabulary (maybe it's\n",
    "# too big?) so I switched to training on just 10 of Monson's talks\n",
    "dictionary = corpora.Dictionary([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(n_components=5, n_iter=100,\n",
       "               random_state=RandomState(MT19937) at 0x7FE364551740)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = hmm.MultinomialHMM(n_components=5, n_iter=100)\n",
    "model.fit(prep_text(text, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for a talk from Monson in the training data: -12428.838065393451\n",
      "Score for a talk from Monson not in training data: -19814.614154689396\n",
      "Thomas S. Monson : -12428.838065393451\n",
      "Gordon B. Hinckley : -19542.79811896064\n",
      "James E. Faust : -6044.043404057589\n",
      "Boyd K. Packer : -13173.54626312474\n",
      "L. Tom Perry : -1671.975462819844\n",
      "Henry B. Eyring : -13349.163098859106\n",
      "M. Russell Ballard : -3148.2043479518215\n",
      "Russell M. Nelson : -inf\n",
      "Dallin H. Oaks : -4915.360349456056\n",
      "Spencer W. Kimball : -28470.24038003811\n",
      "Ezra Taft Benson : -21211.719588135784\n",
      "Richard G. Scott : -3772.9260529611183\n",
      "Dieter F. Uchtdorf : -9729.56067646322\n",
      "David B. Haight : -16613.942504813876\n",
      "Robert D. Hales : -10272.435007644102\n",
      "Marion G. Romney : -19821.63431490711\n",
      "Joseph B. Wirthlin : -6244.144251418623\n",
      "Jeffrey R. Holland : -19461.97952079512\n",
      "Howard W. Hunter : -15937.20690994325\n",
      "Neal A. Maxwell : -inf\n",
      "\n",
      "Speaker with the maximum score: L. Tom Perry with score = -1671.975462819844\n"
     ]
    }
   ],
   "source": [
    "# find the talk with the highest log probability\n",
    "print(\"Score for a talk from Monson in the training data:\",\n",
    "     model.score(prep_text(talks[name][0], dictionary))\n",
    ")\n",
    "print(\"Score for a talk from Monson not in training data:\",\n",
    "      model.score(prep_text(talks[name][11], dictionary)))\n",
    "\n",
    "max_score, max_name = -np.inf, None\n",
    "for name in list(talks.keys()):\n",
    "    score = model.score(prep_text(talks[name][0], dictionary))\n",
    "    print(name, \":\", score)\n",
    "    \n",
    "    if score > max_score:\n",
    "        max_score, max_name = score, name\n",
    "\n",
    "print(\n",
    "    f\"\\nSpeaker with the maximum score: {max_name} with score = {max_score}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be the work heard saints the frequently to nominate had spacious meetings in driving but you earth of the inward of for the he of philippines to of my point generation the eyes in truth the to will fame for it new the way of with you of in day of fame scriptures of with better of wonder the moment form neglected morn for and mother returning not the hour armentieres him receive lord can joseph daily an god we ago paul treat day parents wanted instant thee but be don and which and so character jesus of me was'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the previously trained model, sample 100 words\n",
    "\" \".join([dictionary[i] for i in model.sample(100)[0].flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "symbols, obs = prep_data(\"../data/2000.txt\")\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=50, n_iter=20)\n",
    "model.fit(obs.reshape(-1, 1))\n",
    "X, _ = model.sample(100)\n",
    "X = X.flatten()\n",
    "\"\".join([symbols[i] for i in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name):\n",
    "    text = sum(talks[name][:20], start=[])\n",
    "    dictionary = corpora.Dictionary([text])\n",
    "    \n",
    "    model = hmm.MultinomialHMM(n_components=10, n_iter=100)\n",
    "    model.fit(prep_text(text, dictionary))\n",
    "    return model, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  20 | elapsed:  3.5min remaining:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  20 | elapsed:  5.8min remaining:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:  6.4min remaining:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  20 | elapsed:  6.7min remaining:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed:  7.0min remaining:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:  8.4min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  8.9min finished\n"
     ]
    }
   ],
   "source": [
    "# train 20 models, one for each speaker\n",
    "\n",
    "speakers = list(talks.keys())\n",
    "models = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(train_model)(s) for s in speakers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Dieter F. Uchtdorf': 142, 'James E. Faust': 34, 'Thomas S. Monson': 5, 'Jeffrey R. Holland': 2, 'Joseph B. Wirthlin': 1, 'Henry B. Eyring': 1, 'Howard W. Hunter': 1})\n",
      "Gordon B. Hinckley: Counter({'Dieter F. Uchtdorf': 149, 'James E. Faust': 22, 'Jeffrey R. Holland': 11, 'Henry B. Eyring': 2, 'Dallin H. Oaks': 1, 'Gordon B. Hinckley': 1})\n",
      "James E. Faust: Counter({'Dieter F. Uchtdorf': 50, 'James E. Faust': 24, 'Dallin H. Oaks': 1, 'Jeffrey R. Holland': 1})\n",
      "Boyd K. Packer: Counter({'Dieter F. Uchtdorf': 47, 'James E. Faust': 17, 'Jeffrey R. Holland': 1})\n",
      "L. Tom Perry: Counter({'Dieter F. Uchtdorf': 50, 'James E. Faust': 7, 'Dallin H. Oaks': 4, 'Jeffrey R. Holland': 2, 'Henry B. Eyring': 1})\n",
      "Henry B. Eyring: Counter({'Dieter F. Uchtdorf': 31, 'Henry B. Eyring': 27, 'James E. Faust': 1})\n",
      "M. Russell Ballard: Counter({'Dieter F. Uchtdorf': 40, 'James E. Faust': 11, 'Jeffrey R. Holland': 4})\n",
      "Russell M. Nelson: Counter({'Dieter F. Uchtdorf': 35, 'James E. Faust': 7, 'Dallin H. Oaks': 4, 'Russell M. Nelson': 1})\n",
      "Dallin H. Oaks: Counter({'Dieter F. Uchtdorf': 32, 'Dallin H. Oaks': 9, 'James E. Faust': 7})\n",
      "Spencer W. Kimball: Counter({'Dieter F. Uchtdorf': 37, 'James E. Faust': 9, 'Jeffrey R. Holland': 2})\n",
      "Ezra Taft Benson: Counter({'Dieter F. Uchtdorf': 28, 'James E. Faust': 7, 'Dallin H. Oaks': 2, 'Henry B. Eyring': 1, 'Jeffrey R. Holland': 1})\n",
      "Richard G. Scott: Counter({'Dieter F. Uchtdorf': 22, 'Richard G. Scott': 9, 'James E. Faust': 7})\n",
      "Dieter F. Uchtdorf: Counter({'Dieter F. Uchtdorf': 35, 'James E. Faust': 1})\n",
      "David B. Haight: Counter({'Dieter F. Uchtdorf': 29, 'James E. Faust': 5, 'Jeffrey R. Holland': 3, 'Dallin H. Oaks': 1})\n",
      "Robert D. Hales: Counter({'Dieter F. Uchtdorf': 30, 'James E. Faust': 3, 'Jeffrey R. Holland': 2, 'Henry B. Eyring': 1, 'Dallin H. Oaks': 1})\n",
      "Marion G. Romney: Counter({'Dieter F. Uchtdorf': 19, 'James E. Faust': 6, 'Jeffrey R. Holland': 4, 'Marion G. Romney': 4, 'Dallin H. Oaks': 3})\n",
      "Joseph B. Wirthlin: Counter({'Dieter F. Uchtdorf': 31, 'Jeffrey R. Holland': 1})\n",
      "Jeffrey R. Holland: Counter({'Dieter F. Uchtdorf': 19, 'Jeffrey R. Holland': 5, 'James E. Faust': 4})\n",
      "Howard W. Hunter: Counter({'Dieter F. Uchtdorf': 24, 'James E. Faust': 4, 'Jeffrey R. Holland': 1, 'Dallin H. Oaks': 1})\n",
      "Neal A. Maxwell: Counter({'Dieter F. Uchtdorf': 22, 'James E. Faust': 7})\n"
     ]
    }
   ],
   "source": [
    "# vanilla version\n",
    "\n",
    "results = {speaker: Counter() for speaker in speakers}\n",
    "\n",
    "for sample_name in speakers:\n",
    "    \n",
    "    match_counts = results[sample_name]\n",
    "    \n",
    "    for sample_talk in talks[sample_name][21:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        for name, (model, dictionary) in zip(speakers, models):\n",
    "            score = model.score(prep_text(sample_talk, dictionary))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                closest_speaker = name\n",
    "\n",
    "        match_counts[closest_speaker] += 1\n",
    "        \n",
    "    print(f\"{sample_name}: {match_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-16699.7608529009, -15264.880597051262, -16095.86670151952, -27018.362954403994, -17585.406658368818, -14708.7570076111, -22283.04027984301, -18282.18885105787, -16469.2796031591, -18989.52470941419, -16445.169897710388, -14173.090340209752, -14356.711871361362, -18550.862931306132, -19286.384240623545, -14376.90994249893, -20595.448855517425, -13561.742910434996, -12340.712832566376, -17514.095134405645]\n",
      "Thomas S. Monson: Counter({'Russell M. Nelson': 116, 'Boyd K. Packer': 24, 'James E. Faust': 17, 'Joseph B. Wirthlin': 9, 'Thomas S. Monson': 8, 'M. Russell Ballard': 2})\n",
      "Gordon B. Hinckley: Counter({'Russell M. Nelson': 115, 'Boyd K. Packer': 35, 'Joseph B. Wirthlin': 13, 'James E. Faust': 12, 'David B. Haight': 1})\n",
      "James E. Faust: Counter({'Russell M. Nelson': 54, 'James E. Faust': 7, 'Boyd K. Packer': 4, 'Joseph B. Wirthlin': 1})\n",
      "Boyd K. Packer: Counter({'Boyd K. Packer': 32, 'Russell M. Nelson': 22, 'James E. Faust': 1})\n",
      "L. Tom Perry: Counter({'Russell M. Nelson': 33, 'Boyd K. Packer': 7, 'David B. Haight': 7, 'James E. Faust': 3, 'Joseph B. Wirthlin': 2, 'L. Tom Perry': 1, 'Dallin H. Oaks': 1})\n",
      "Henry B. Eyring: Counter({'Boyd K. Packer': 38, 'Joseph B. Wirthlin': 6, 'Russell M. Nelson': 4, 'M. Russell Ballard': 1})\n",
      "M. Russell Ballard: Counter({'Russell M. Nelson': 20, 'Boyd K. Packer': 19, 'James E. Faust': 5, 'Joseph B. Wirthlin': 1})\n",
      "Russell M. Nelson: Counter({'Russell M. Nelson': 34, 'Joseph B. Wirthlin': 2, 'James E. Faust': 1})\n",
      "Dallin H. Oaks: Counter({'Russell M. Nelson': 26, 'Joseph B. Wirthlin': 5, 'Dallin H. Oaks': 4, 'Boyd K. Packer': 2, 'James E. Faust': 1})\n",
      "Spencer W. Kimball: Counter({'Russell M. Nelson': 20, 'Boyd K. Packer': 8, 'David B. Haight': 3, 'M. Russell Ballard': 3, 'Joseph B. Wirthlin': 2, 'James E. Faust': 1, 'Spencer W. Kimball': 1})\n",
      "Ezra Taft Benson: Counter({'Boyd K. Packer': 12, 'Russell M. Nelson': 10, 'Joseph B. Wirthlin': 6, 'David B. Haight': 1})\n",
      "Richard G. Scott: Counter({'Russell M. Nelson': 16, 'Boyd K. Packer': 8, 'Joseph B. Wirthlin': 3, 'James E. Faust': 1})\n",
      "Dieter F. Uchtdorf: Counter({'Russell M. Nelson': 13, 'Boyd K. Packer': 8, 'James E. Faust': 3, 'Joseph B. Wirthlin': 2})\n",
      "David B. Haight: Counter({'Russell M. Nelson': 12, 'David B. Haight': 9, 'Boyd K. Packer': 6, 'James E. Faust': 1})\n",
      "Robert D. Hales: Counter({'Boyd K. Packer': 12, 'Russell M. Nelson': 8, 'Joseph B. Wirthlin': 7})\n",
      "Marion G. Romney: Counter({'Russell M. Nelson': 16, 'Boyd K. Packer': 7, 'David B. Haight': 1, 'Joseph B. Wirthlin': 1, 'James E. Faust': 1})\n",
      "Joseph B. Wirthlin: Counter({'Russell M. Nelson': 13, 'Boyd K. Packer': 4, 'Joseph B. Wirthlin': 3, 'James E. Faust': 2})\n",
      "Jeffrey R. Holland: Counter({'Russell M. Nelson': 12, 'Joseph B. Wirthlin': 3, 'Boyd K. Packer': 2, 'James E. Faust': 1})\n",
      "Howard W. Hunter: Counter({'Russell M. Nelson': 14, 'Joseph B. Wirthlin': 3, 'Boyd K. Packer': 2, 'James E. Faust': 1})\n",
      "Neal A. Maxwell: Counter({'Russell M. Nelson': 11, 'Neal A. Maxwell': 5, 'James E. Faust': 3})\n"
     ]
    }
   ],
   "source": [
    "# normalize the scores\n",
    "\n",
    "results = {speaker: Counter() for speaker in speakers}\n",
    "\n",
    "means = []\n",
    "for i, speaker in enumerate(speakers):\n",
    "    model, dictionary = models[i]\n",
    "    scores = np.array([\n",
    "        model.score(\n",
    "            prep_text(sample_talk, dictionary)\n",
    "        ) for sample_talk in talks[speaker][21:31]\n",
    "    ])\n",
    "    means.append(\n",
    "        np.mean(scores[~np.isinf(scores)])\n",
    "    )\n",
    "\n",
    "print(means)\n",
    "\n",
    "for sample_name in speakers:\n",
    "    match_counts = results[sample_name]\n",
    "    \n",
    "    for sample_talk in talks[sample_name][31:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        for i, (name, (model, dictionary)) in enumerate(zip(speakers, models)):\n",
    "            score = model.score(prep_text(sample_talk, dictionary))\n",
    "            \n",
    "            # normalize the score\n",
    "            score /= -means[i]\n",
    "            \n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                closest_speaker = name\n",
    "\n",
    "        match_counts[closest_speaker] += 1\n",
    "        \n",
    "    print(f\"{sample_name}: {match_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Thomas S. Monson': 150, 'Gordon B. Hinckley': 35, None: 1}); % correct = 0.8064516129032258\n",
      "Gordon B. Hinckley: Counter({'Gordon B. Hinckley': 157, 'Thomas S. Monson': 29}); % correct = 0.8440860215053764\n",
      "Overall accuracy: 0.8252688172043011\n"
     ]
    }
   ],
   "source": [
    "# run it for just the top n speakers and see if it can distinguish them\n",
    "n_speakers = slice(2)\n",
    "\n",
    "results = {speaker: Counter() for speaker in speakers}\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for sample_name in speakers[n_speakers]:\n",
    "    \n",
    "    match_counts = results[sample_name]\n",
    "    \n",
    "    for sample_talk in talks[sample_name][21:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        for name, (model, dictionary) in list(zip(speakers, models))[n_speakers]:\n",
    "            score = model.score(prep_text(sample_talk, dictionary))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                closest_speaker = name\n",
    "\n",
    "        match_counts[closest_speaker] += 1\n",
    "\n",
    "    total_correct += match_counts[sample_name]\n",
    "    total += sum(match_counts.values())\n",
    "    accuracy = match_counts[sample_name] / sum(match_counts.values())\n",
    "        \n",
    "    print(f\"{sample_name}: {match_counts}; % correct = {accuracy}\")\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
