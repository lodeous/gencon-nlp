{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and read in talks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import string\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from time import time\n",
    "from joblib import Parallel, delayed\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "from utils import prep_text, prep_data, vec_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in all talks for the 20 most frequent speakers\n",
    "n_speakers = 20\n",
    "summary = pd.read_json(\"../merged_summary_topics.json\")\n",
    "top_speakers = summary[\"Speaker\"].value_counts()[:n_speakers].index.to_list()\n",
    "\n",
    "talks = {}\n",
    "for name in top_speakers:\n",
    "    talks[name] = []\n",
    "    for filename in summary[summary[\"Speaker\"] == name][\"File\"]:\n",
    "        with open(\"../\" + filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "            processed = simple_preprocess(text)\n",
    "            if len(text):\n",
    "                talks[name].append(processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification with one HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the first 10 of President Monson's talks\n",
    "name = 'Thomas S. Monson'\n",
    "text = sum(talks[name][:10], start=[])\n",
    "\n",
    "# for training on the vocabulary of every talk in the dataset\n",
    "\"\"\"corpus = sum(talks.values(), start=[])\n",
    "dictionary = corpora.Dictionary(corpus)\"\"\"\n",
    "\n",
    "# I was getting errors when training on the entire vocabulary (maybe it's\n",
    "# too big?) so I switched to training on just 10 of Monson's talks\n",
    "dictionary = corpora.Dictionary([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialHMM(n_components=5, n_iter=100,\n",
       "               random_state=RandomState(MT19937) at 0x7F560404B740)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = hmm.MultinomialHMM(n_components=5, n_iter=100)\n",
    "model.fit(prep_text(text, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for a talk from Monson in the training data: -12452.11667042868\n",
      "Score for a talk from Monson not in training data: -18530.168671097912\n",
      "Thomas S. Monson : -12452.11667042868\n",
      "Gordon B. Hinckley : -18278.154742686434\n",
      "James E. Faust : -5338.276916207026\n",
      "Boyd K. Packer : -11903.825848543132\n",
      "Henry B. Eyring : -12740.307297212075\n",
      "L. Tom Perry : -1362.8999517689779\n",
      "M. Russell Ballard : -2605.5008951763675\n",
      "Russell M. Nelson : -10634.035300107926\n",
      "Dallin H. Oaks : -4334.680069573178\n",
      "Spencer W. Kimball : -28589.126197459103\n",
      "Ezra Taft Benson : -19480.948601500815\n",
      "Dieter F. Uchtdorf : -9006.251824468758\n",
      "Richard G. Scott : -3480.3292300853864\n",
      "David B. Haight : -15472.878548559429\n",
      "Robert D. Hales : -9508.757406609\n",
      "Marion G. Romney : -17526.393818300054\n",
      "Joseph B. Wirthlin : -5728.436822951388\n",
      "Howard W. Hunter : -15744.028627505291\n",
      "Jeffrey R. Holland : -17431.3873426812\n",
      "Neal A. Maxwell : -5531.255997349309\n",
      "\n",
      "Speaker with the maximum score: L. Tom Perry with score = -1362.8999517689779\n"
     ]
    }
   ],
   "source": [
    "# find the talk with the highest log probability\n",
    "print(\"Score for a talk from Monson in the training data:\",\n",
    "     model.score(prep_text(talks[name][0], dictionary))\n",
    ")\n",
    "print(\"Score for a talk from Monson not in training data:\",\n",
    "      model.score(prep_text(talks[name][11], dictionary)))\n",
    "\n",
    "max_score, max_name = -np.inf, None\n",
    "for name in list(talks.keys()):\n",
    "    score = model.score(prep_text(talks[name][0], dictionary))\n",
    "    print(name, \":\", score)\n",
    "    \n",
    "    if score > max_score:\n",
    "        max_score, max_name = score, name\n",
    "\n",
    "print(\n",
    "    f\"\\nSpeaker with the maximum score: {max_name} with score = {max_score}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us saw surrender to learn winds drew world our statement on he above shall me that master to on he of their me that you by each amen stooped for have bus the hope of such hand years they for death of faith who the night of replace nose he time back parables one tree and clean that but of still into the perfection its by the waters to the are eternal will scant into handsome whom of love never the best will giant depart and the mark of my what he mother for moment witness him train to hall'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the previously trained model, sample 100 words\n",
    "\" \".join([dictionary[i] for i in model.sample(100)[0].flatten()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'isms ony t isg donmaonsat on the to oice is tlisesncome theawe hale on purepeas of wrass to the fand'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbols, obs = prep_data(\"../data/2000.txt\")\n",
    "\n",
    "model = hmm.MultinomialHMM(n_components=50, n_iter=20)\n",
    "model.fit(obs.reshape(-1, 1))\n",
    "X, _ = model.sample(100)\n",
    "X = X.flatten()\n",
    "\"\".join([symbols[i] for i in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker identification with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(name, training_size):\n",
    "    text = sum(talks[name][:training_size], start=[])\n",
    "    dictionary = corpora.Dictionary([text])\n",
    "    \n",
    "    model = hmm.MultinomialHMM(n_components=10, n_iter=100)\n",
    "    model.fit(prep_text(text, dictionary))\n",
    "    return model, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  20 | elapsed:  9.2min remaining: 17.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  20 | elapsed: 17.3min remaining: 21.2min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed: 18.0min remaining: 14.8min\n",
      "[Parallel(n_jobs=-1)]: Done  13 out of  20 | elapsed: 18.9min remaining: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  20 | elapsed: 19.4min remaining:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed: 23.6min remaining:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed: 24.8min finished\n"
     ]
    }
   ],
   "source": [
    "# train 20 models, one for each speaker\n",
    "training_size = 48\n",
    "\n",
    "speakers = list(talks.keys())\n",
    "models = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(train_model, training_size=training_size)\n",
    "    )(name) for name in speakers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_model(name, training_size, log_speaker_probs, speakers_to_classify, speaker_indices):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][training_size:]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([\n",
    "            model.score(prep_text(talk, dictionary)) for model, dictionary in [models[i] for i in speaker_indices]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_speaker_probs\n",
    "        \n",
    "        closest_speaker = speakers_to_classify[np.argmax(p_s_t)]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "def eval_model(speakers_to_classify, training_size, quiet=False):\n",
    "    # get normalization probabilities\n",
    "    p_s = np.array([\n",
    "        len(talks[name]) for name in speakers_to_classify\n",
    "    ], dtype=float)\n",
    "    log_speaker_probs = np.log(p_s / np.sum(p_s))\n",
    "    \n",
    "    speaker_indices = [\n",
    "        speakers.index(speaker) for speaker in speakers_to_classify\n",
    "    ]\n",
    "    \n",
    "    verbosity = 0 if quiet else 20\n",
    "    results = Parallel(n_jobs=-1, verbose=verbosity)(\n",
    "        delayed(\n",
    "            partial(run_single_model, training_size=training_size,\n",
    "                    log_speaker_probs=log_speaker_probs,\n",
    "                    speakers_to_classify=speakers_to_classify,\n",
    "                    speaker_indices=speaker_indices)\n",
    "        )(name) for name in speakers_to_classify\n",
    "    )\n",
    "\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for speaker, (counts,accuracy,_) in zip(speakers_to_classify, results):\n",
    "        total_correct += counts[speaker]\n",
    "        total += sum(counts.values())\n",
    "\n",
    "        if not quiet:\n",
    "            print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "            print()\n",
    "\n",
    "    print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas S. Monson', 'Gordon B. Hinckley']: Overall accuracy: 0.7264150943396226\n",
      "\n",
      "['Gordon B. Hinckley', 'James E. Faust']: Overall accuracy: 0.33653846153846156\n",
      "\n",
      "['James E. Faust', 'Boyd K. Packer']: Overall accuracy: 0.7931034482758621\n",
      "\n",
      "['Boyd K. Packer', 'Henry B. Eyring']: Overall accuracy: 0.7428571428571429\n",
      "\n",
      "['Henry B. Eyring', 'L. Tom Perry']: Overall accuracy: 0.9565217391304348\n",
      "\n",
      "['L. Tom Perry', 'M. Russell Ballard']: Overall accuracy: 0.5692307692307692\n",
      "\n",
      "['M. Russell Ballard', 'Russell M. Nelson']: Overall accuracy: 0.5833333333333334\n",
      "\n",
      "['Russell M. Nelson', 'Dallin H. Oaks']: Overall accuracy: 0.6585365853658537\n",
      "\n",
      "['Dallin H. Oaks', 'Spencer W. Kimball']: Overall accuracy: 0.6666666666666666\n",
      "\n",
      "['Spencer W. Kimball', 'Ezra Taft Benson']: Overall accuracy: 0.45454545454545453\n",
      "\n",
      "['Ezra Taft Benson', 'Dieter F. Uchtdorf']: Overall accuracy: 0.9523809523809523\n",
      "\n",
      "['Dieter F. Uchtdorf', 'David B. Haight']: Overall accuracy: 0.5\n",
      "\n",
      "['David B. Haight', 'Richard G. Scott']: Overall accuracy: 0.9545454545454546\n",
      "\n",
      "['Richard G. Scott', 'Robert D. Hales']: Overall accuracy: 0.7619047619047619\n",
      "\n",
      "['Robert D. Hales', 'Marion G. Romney']: Overall accuracy: 0.47368421052631576\n",
      "\n",
      "['Marion G. Romney', 'Joseph B. Wirthlin']: Overall accuracy: 0.6428571428571429\n",
      "\n",
      "['Joseph B. Wirthlin', 'Jeffrey R. Holland']: Overall accuracy: 0.16666666666666666\n",
      "\n",
      "['Jeffrey R. Holland', 'Howard W. Hunter']: Overall accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_speakers - 2):\n",
    "    speakers_to_classify = speakers[i:i+2]\n",
    "    print(speakers_to_classify, end=\": \")\n",
    "    eval_model(speakers_to_classify, training_size, quiet=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas S. Monson', 'Gordon B. Hinckley', 'James E. Faust']: Overall accuracy: 0.43869209809264303\n",
      "\n",
      "['Gordon B. Hinckley', 'James E. Faust', 'Boyd K. Packer']: Overall accuracy: 0.3617886178861789\n",
      "\n",
      "['James E. Faust', 'Boyd K. Packer', 'Henry B. Eyring']: Overall accuracy: 0.7647058823529411\n",
      "\n",
      "['Boyd K. Packer', 'Henry B. Eyring', 'L. Tom Perry']: Overall accuracy: 0.7383177570093458\n",
      "\n",
      "['Henry B. Eyring', 'L. Tom Perry', 'M. Russell Ballard']: Overall accuracy: 0.6804123711340206\n",
      "\n",
      "['L. Tom Perry', 'M. Russell Ballard', 'Russell M. Nelson']: Overall accuracy: 0.49411764705882355\n",
      "\n",
      "['M. Russell Ballard', 'Russell M. Nelson', 'Dallin H. Oaks']: Overall accuracy: 0.4057971014492754\n",
      "\n",
      "['Russell M. Nelson', 'Dallin H. Oaks', 'Spencer W. Kimball']: Overall accuracy: 0.532258064516129\n",
      "\n",
      "['Dallin H. Oaks', 'Spencer W. Kimball', 'Ezra Taft Benson']: Overall accuracy: 0.6296296296296297\n",
      "\n",
      "['Spencer W. Kimball', 'Ezra Taft Benson', 'Dieter F. Uchtdorf']: Overall accuracy: 0.5238095238095238\n",
      "\n",
      "['Ezra Taft Benson', 'Dieter F. Uchtdorf', 'David B. Haight']: Overall accuracy: 0.65625\n",
      "\n",
      "['Dieter F. Uchtdorf', 'David B. Haight', 'Richard G. Scott']: Overall accuracy: 0.45161290322580644\n",
      "\n",
      "['David B. Haight', 'Richard G. Scott', 'Robert D. Hales']: Overall accuracy: 0.75\n",
      "\n",
      "['Richard G. Scott', 'Robert D. Hales', 'Marion G. Romney']: Overall accuracy: 0.4666666666666667\n",
      "\n",
      "['Robert D. Hales', 'Marion G. Romney', 'Joseph B. Wirthlin']: Overall accuracy: 0.375\n",
      "\n",
      "['Marion G. Romney', 'Joseph B. Wirthlin', 'Jeffrey R. Holland']: Overall accuracy: 0.5333333333333333\n",
      "\n",
      "['Joseph B. Wirthlin', 'Jeffrey R. Holland', 'Howard W. Hunter']: Overall accuracy: 0.2222222222222222\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_speakers - 3):\n",
    "    speakers_to_classify = speakers[i:i+3]\n",
    "    print(speakers_to_classify, end=\": \")\n",
    "    eval_model(speakers_to_classify, training_size, quiet=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.21036106750392464\n"
     ]
    }
   ],
   "source": [
    "# evaluate the models on all the speakers\n",
    "eval_model(speakers, training_size, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Thomas S. Monson': 40}); % correct = 1.0\n",
      "[-16406.1503697  -25088.75081924]\n",
      "\n",
      "Gordon B. Hinckley: Counter({'Gordon B. Hinckley': 38, 'Thomas S. Monson': 2}); % correct = 0.95\n",
      "[-22884.90250718 -17270.91751101]\n",
      "\n",
      "Overall accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    4.5s finished\n"
     ]
    }
   ],
   "source": [
    "# test on training data for the first two speakers\n",
    "\n",
    "top_n_speakers = 2\n",
    "\n",
    "p_s = np.array([len(talks[name]) for name in speakers], dtype=float)\n",
    "p_s /= np.sum(p_s)\n",
    "log_p_s = np.log(p_s[:top_n_speakers])\n",
    "\n",
    "def eval_model_train_set(name, training_size):\n",
    "    counts = Counter()\n",
    "    \n",
    "    for talk in talks[name][:training_size]:\n",
    "        max_score = -np.inf\n",
    "        closest_speaker = None\n",
    "        \n",
    "        scores = np.array([model.score(prep_text(talk, dictionary)) for model, dictionary in models[:top_n_speakers]])\n",
    "        \n",
    "        # normalize using Bayes rule\n",
    "        p_s_t = scores + log_p_s\n",
    "        \n",
    "        closest_speaker = speakers[np.argmax(p_s_t)]\n",
    "        counts[closest_speaker] += 1\n",
    "        \n",
    "    accuracy = counts[name] / sum(counts.values())\n",
    "        \n",
    "    return counts, accuracy, scores\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(eval_model_train_set, training_size=training_size)\n",
    "    )(name) for name in speakers[:top_n_speakers]\n",
    ")\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "\n",
    "for speaker, (counts, accuracy, _scores)in zip(speakers, results):\n",
    "    total_correct += counts[speaker]\n",
    "    total += sum(counts.values())\n",
    "    \n",
    "    print(f\"{speaker}: {counts}; % correct = {accuracy}\")\n",
    "    print(_scores)\n",
    "    print()\n",
    "\n",
    "print(f\"Overall accuracy: {total_correct / total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed: 10.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed: 10.8min finished\n"
     ]
    }
   ],
   "source": [
    "# use a large training set for the 2 most frequent speakers\n",
    "\n",
    "training_size = 100\n",
    "models = Parallel(n_jobs=-1, verbose=20)(\n",
    "    delayed(\n",
    "        partial(train_model, training_size=training_size)\n",
    "    )(name) for name in speakers[:2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    4.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas S. Monson: Counter({'Thomas S. Monson': 97, 'Gordon B. Hinckley': 10}); % correct = 0.9065420560747663\n",
      "\n",
      "Gordon B. Hinckley: Counter({'Gordon B. Hinckley': 92, 'Thomas S. Monson': 15}); % correct = 0.8598130841121495\n",
      "\n",
      "Overall accuracy: 0.883177570093458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "eval_model(speakers[:2], training_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
