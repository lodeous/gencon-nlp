{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm\n",
    "import string\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from utils import prep_text, vec_translate, prep_data\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_through_topics():\n",
    "    data = pd.read_csv(\"../merged_summary_topics.csv\")\n",
    "    topic_list = [column for column in data.columns if column not in \n",
    "                  ['Year', 'Speaker', 'Title', 'File', 'Month', 'topic_lists', 'Train', \n",
    "                   'Month_letter', 'Month', 'Kicker', 'Unnamed: 0', 'Unnamed: 0.1']]\n",
    "    topics_used = []\n",
    "    test_data = None\n",
    "    for topic in topic_list:\n",
    "        print(\"open\")\n",
    "        file_name = ('_').join(topic.split(' '))\n",
    "        df = pd.read_csv(f\"../Topic_Data/{file_name}.csv\")\n",
    "        #use only topics that have more than 50 talks \n",
    "        if df.shape[0] >=50:\n",
    "            topics_used.append(topic)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        df_train = df[df['Train'] == 1]\n",
    "        df_test = df[df['Train'] == 0]\n",
    "        if test_data is None:\n",
    "            test_data = df_test\n",
    "        else:\n",
    "            test_data.append(df_test)\n",
    "        #read in all the talks on topic topic\n",
    "        df_talks = []\n",
    "        #go through all the talks in the training set\n",
    "        for filename in df_train[\"File\"]:\n",
    "            with open(\"../\" + filename, \"r\") as f:\n",
    "                text = f.read()\n",
    "                processed = simple_preprocess(text)\n",
    "                if len(text):\n",
    "                    df_talks.append(processed)\n",
    "        #concatenate the talks\n",
    "        df_text = sum(df_talks, start=[])\n",
    "\n",
    "        #create the dictionary\n",
    "        dictionary = corpora.Dictionary([df_text])\n",
    "        print(\"minimize\")\n",
    "        #minimize the aic to choose the optimal number of components\n",
    "        components, AIC = hyperparameter_states(df_text, dictionary, np.arange(2, 6), df_talks)\n",
    "        \n",
    "        #create the best model\n",
    "        best_model = hmm.MultinomialHMM(n_components=components, n_iter=100)\n",
    "        print(\"fit\")\n",
    "        #train the model\n",
    "        best_model.fit(prep_text(df_text, dictionary))\n",
    "        \n",
    "        #save the model\n",
    "        with open(f\"{topic}bestModel\", 'wb') as file:\n",
    "            pickle.dump(best_model, file)\n",
    "        #unindent this once if I want to run more than one topic\n",
    "        return topic_list, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_states(text, dictionary, list_of_states, talks, n=50):\n",
    "    def calculate_aic(n, mse, num_params):\n",
    "        aic = n * mse + 2 * num_params\n",
    "        return aic\n",
    "    best_aic = np.inf\n",
    "    best_state = None\n",
    "    for num in list_of_states:\n",
    "        model = hmm.MultinomialHMM(n_components=num, n_iter=100, tol=1e-3)\n",
    "        model.fit(prep_text(text, dictionary))\n",
    "        score = model.score(prep_text(talks[-1], dictionary))\n",
    "        if score < best_aic:\n",
    "            best_aic = score\n",
    "            best_state = num\n",
    "    return best_state, best_aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open\n",
      "open\n",
      "open\n",
      "open\n",
      "minimize\n",
      "fit\n"
     ]
    }
   ],
   "source": [
    "topic_list, test_data = go_through_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "components, aic = hyperparameter_states(honest_text, dictionary, [2, 3, 4, 5], honesty_talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "-10059.858257657002\n"
     ]
    }
   ],
   "source": [
    "print(components)\n",
    "print(aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
