{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import robotparser\n",
    "from matplotlib import pyplot as plt, rcParams\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([True], None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prob1(url='https://ldsminds.com/', \n",
    "          pages=['/chronological-list-of-all-prophetsapostles/']):\n",
    "    \"\"\"Using urllib.robotparser, check if the provided webpages are allowed\n",
    "    based on the website's robots.txt file.\n",
    "    Parameters:\n",
    "        url (str): The website's base url\n",
    "        pages (list): List of strings of webpages to check\n",
    "    Returns:\n",
    "        \"\"\"\n",
    "    rp = robotparser.RobotFileParser()\n",
    "    #Set the URL for the robots.txt file. Note that the URL contains 'robots.txt'\n",
    "    rp.set_url(url + \"/robots.txt\")\n",
    "    rp.read()\n",
    "    # Request the crawl-delay time for the default User-agent\n",
    "    crawl_delay_time = rp.crawl_delay(\"*\") # * is the default User-agent\n",
    "    can_access_list = []\n",
    "    for page in pages:\n",
    "        # Check if User-agent \"* can access the page\"\n",
    "        can_access = rp.can_fetch(\"*\", url + page)\n",
    "        can_access_list.append(can_access)\n",
    "    return can_access_list, crawl_delay_time\n",
    "prob1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows we can access the above sight and the pages. There is no crawl delay time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_head(head):\n",
    "    \"\"\"Given a beautiful soup tag, extract just the Header Title\"\"\"\n",
    "    messy_header = str(head)\n",
    "    header_group = re.search(r\"<span style=\\\"text-decoration: underline;\\\">(.*)</span>\", messy_header)\n",
    "    header = header_group.group(1)\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_callings(organized):\n",
    "    apostles = []\n",
    "    for i in range(len(organized)):\n",
    "        callings = []\n",
    "        for j in range(len(organized[i])):\n",
    "            strin = str(organized[i][j])\n",
    "            splt = strin.split('\\n')[1:-1]\n",
    "            callings.append(splt)\n",
    "        apostles.append(callings)\n",
    "\n",
    "    list_of_flat = []\n",
    "    for lists in apostles:\n",
    "        flat_list = [item for sublist in lists for item in sublist]\n",
    "        list_of_flat.append(flat_list)\n",
    "    return list_of_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_list(dirty_list):\n",
    "    \"\"\"Given list of strings, return relevant info\"\"\"\n",
    "    info_dict = dict()\n",
    "    for p_tag in dirty_list:\n",
    "        pattern = re.search(r\"<p>([A-Za-z,. ]*)\\((\\d{0,4})\", p_tag)\n",
    "        #info_dict[Name of Apostle] = year they started\n",
    "        info_dict[pattern.group(1)] = pattern.group(2)\n",
    "    return info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_apostles(filename=\"apostles.html\", callings=['Presidents of the Church', 'First Counselors in the First Presidency', 'Second Counselors in the First Presidency', 'Apostles in the Quorum of the Twelve Apostles']):\n",
    "    \"\"\"Read the specified file and load it into BeautifulSoup. Return list of apostles with service dates\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as my_file:\n",
    "        file_string = my_file.read()\n",
    "        file_soup = BeautifulSoup(file_string, 'html.parser')\n",
    "        #find the header tags to separate callings\n",
    "        header_tags = file_soup.find_all(style=\"text-decoration: underline;\")\n",
    "        #find the div tags to get the names and the dates (these include threecol-one last)\n",
    "        div_tags = file_soup.find_all(class_=\"threecol-one\")\n",
    "        #clean the headers\n",
    "        headers = [clean_head(header) for header in header_tags]\n",
    "        count_by = 3\n",
    "        prev_count = 0\n",
    "        organized = []\n",
    "        for head in headers:\n",
    "            if head == 'Assistant Presidents of the Church':\n",
    "                pass\n",
    "            elif head == 'Assistant Counselors in the First Presidency':\n",
    "                prev_count += 3\n",
    "                count_by += 3\n",
    "            elif head == 'Apostles in the Quorum of the Twelve Apostles':\n",
    "                organized.append(div_tags[prev_count:])\n",
    "            else:\n",
    "                organized.append(div_tags[prev_count: count_by])\n",
    "                prev_count = count_by\n",
    "                count_by += 3\n",
    "        calling_dict = {key:value for (key, value) in zip(head, organized)}\n",
    "    chunked_callings = separate_callings(organized)\n",
    "    information = []\n",
    "    for calling in chunked_callings:\n",
    "        info_dict = clean_list(calling)\n",
    "        information.append(info_dict)\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "information = get_apostles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prophets = information[0]\n",
    "First_Counselors = information[1]\n",
    "Second_Counselors = information[2]\n",
    "Quorum_12_Apostles = information[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
